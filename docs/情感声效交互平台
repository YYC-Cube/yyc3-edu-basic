# YYCÂ³â¤ï¸AI
ã€Œä¸‡è±¡å½’å…ƒäºäº‘æ¢ã€æƒ…æ„ŸåŒ–æ™ºèƒ½AIè®¾è®¡ç³»ç»Ÿæ¶æ„ææ¡ˆ
## ä¸€ã€ç³»ç»Ÿé«˜å±‚çº§æŠ€æœ¯æ¶æ„
### 1. æ•´ä½“æ¶æ„è®¾è®¡
```plaintext
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    å‰ç«¯äº¤äº’å±‚                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    åç«¯æœåŠ¡å±‚                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    æ•°æ®å­˜å‚¨å±‚                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 å¤šæ¨¡æ€èåˆå¼•æ“                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```
### 2. å„å±‚è¯¦ç»†è®¾è®¡ä¸æŠ€æœ¯æ ˆ
#### 2.1 å‰ç«¯äº¤äº’å±‚
åŠŸèƒ½å®šä½ï¼šä½œä¸ºç”¨æˆ·ä¸ç³»ç»Ÿçš„æƒ…æ„Ÿäº¤äº’ç•Œé¢ï¼Œå®ç°å¤šæ¨¡æ€è¾“å…¥æ•æ‰ä¸æƒ…æ„ŸåŒ–åé¦ˆã€‚
æ ¸å¿ƒæŠ€æœ¯æ ˆï¼š
- è¯­è¨€ä¸æ¡†æ¶ï¼šTypeScript, React 18+ (Next.js)
- çŠ¶æ€ç®¡ç†ï¼šRedux Toolkit + Zustand
- UIç»„ä»¶åº“ï¼šMaterial-UI (MUI) / è‡ªç ”è®¾è®¡ç³»ç»Ÿ
- åŠ¨ç”»è§£å†³æ–¹æ¡ˆï¼šFramer Motion + GSAP
- CSSæ–¹æ¡ˆï¼šStyled Components / Emotion
- éŸ³è§†é¢‘å¤„ç†ï¼šWeb Audio API, MediaRecorder API
- å¯è§†åŒ–åº“ï¼šD3.js, ECharts, Three.js
- AIå‰ç«¯æ¨ç†ï¼šTensorFlow.js
å…³é”®ç»„ä»¶ï¼š
- å¤šæ¨¡æ€è¾“å…¥æ•æ‰å™¨ï¼ˆæ–‡æœ¬ã€è¯­éŸ³ã€è§†è§‰ã€è¡Œä¸ºï¼‰
- æƒ…æ„ŸçŠ¶æ€ç®¡ç†å™¨
- åŠ¨æ€ä¸»é¢˜ç”Ÿæˆå™¨
- æƒ…æ„ŸåŒ–æ¸²æŸ“å¼•æ“
- å¤šæ„Ÿå®˜åé¦ˆåè°ƒå™¨
#### 2.2 åç«¯æœåŠ¡å±‚
åŠŸèƒ½å®šä½ï¼šæä¾›AIæœåŠ¡ã€ä¸šåŠ¡é€»è¾‘å¤„ç†å’Œç³»ç»Ÿåè°ƒèƒ½åŠ›ã€‚
æ ¸å¿ƒæŠ€æœ¯æ ˆï¼š
- ä¸»è¯­è¨€ä¸æ¡†æ¶ï¼šPython (FastAPI), Node.js (NestJS)
- APIç½‘å…³ï¼šKong
- æœåŠ¡ç¼–æ’ï¼šApache Airflow
- æ¶ˆæ¯é˜Ÿåˆ—ï¼šRabbitMQ / Kafka
- å®¹å™¨åŒ–ï¼šDocker, Kubernetes
- RPCæ¡†æ¶ï¼šgRPC
æ ¸å¿ƒæœåŠ¡ï¼š
- æƒ…æ„Ÿåˆ†ææœåŠ¡
- å¤šæ¨¡æ€å¤„ç†æœåŠ¡
- ç”¨æˆ·ç”»åƒæœåŠ¡
- ä¸ªæ€§åŒ–æ¨èæœåŠ¡
- ç³»ç»Ÿç¼–æ’æœåŠ¡
#### 2.3 æ•°æ®å­˜å‚¨å±‚
åŠŸèƒ½å®šä½ï¼šå­˜å‚¨å’Œç®¡ç†ç³»ç»Ÿå„ç±»æ•°æ®ï¼Œæ”¯æŒé«˜æ•ˆæŸ¥è¯¢ä¸åˆ†æã€‚
æ ¸å¿ƒæŠ€æœ¯æ ˆï¼š
- å…³ç³»å‹æ•°æ®åº“ï¼šPostgreSQL
- NoSQLæ•°æ®åº“ï¼šMongoDB
- å‘é‡æ•°æ®åº“ï¼šPinecone / Milvus
- å›¾æ•°æ®åº“ï¼šNeo4j
- ç¼“å­˜ç³»ç»Ÿï¼šRedis
- å¯¹è±¡å­˜å‚¨ï¼šAWS S3 / é˜¿é‡Œäº‘OSS
- æœç´¢å¼•æ“ï¼šElasticsearch
æ•°æ®åˆ†ç±»ï¼š
- ç”¨æˆ·æ•°æ®ä¸ç”»åƒ
- æƒ…æ„ŸçŠ¶æ€å†å²
- å¤šæ¨¡æ€å†…å®¹èµ„æº
- ç³»ç»Ÿé…ç½®ä¸è§„åˆ™
- æ¨¡å‹å‚æ•°ä¸å…ƒæ•°æ®
#### 2.4 å¤šæ¨¡æ€èåˆå¼•æ“
åŠŸèƒ½å®šä½ï¼šç³»ç»Ÿæ ¸å¿ƒï¼Œå®ç°å¤šæ¨¡æ€æ•°æ®çš„èåˆå¤„ç†ä¸æƒ…æ„Ÿæ™ºèƒ½ã€‚
æ ¸å¿ƒæŠ€æœ¯æ ˆï¼š
- NLPå¤„ç†ï¼šTransformers (Hugging Face), spaCy
- è¯­éŸ³å¤„ç†ï¼šLibrosa, DeepSpeech
- è§†è§‰å¤„ç†ï¼šOpenCV, MediaPipe
- æƒ…æ„Ÿåˆ†æï¼šVADER, DeepAffects API
- æœºå™¨å­¦ä¹ æ¡†æ¶ï¼šTensorFlow, PyTorch
- æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼šBERT, GPT, ViT, CLIP
æ ¸å¿ƒæ¨¡å—ï¼š
- å¤šæ¨¡æ€ç‰¹å¾æå–å™¨
- æƒ…æ„ŸçŠ¶æ€æ¨ç†æœº
- ä¸Šä¸‹æ–‡ç†è§£å¼•æ“
- ä¸ªæ€§åŒ–å“åº”ç”Ÿæˆå™¨
- è‡ªé€‚åº”å­¦ä¹ ç³»ç»Ÿ
### 3. æƒ…æ„ŸåŒ–æ™ºèƒ½ä¸å¤šæ¨¡æ€èåˆçš„å…³é”®å®ç°
#### 3.1 æƒ…æ„ŸåŒ–æ™ºèƒ½å®ç°
æƒ…æ„Ÿæ„ŸçŸ¥ï¼š
- å®ç°å¤šé€šé“æƒ…æ„Ÿæ•°æ®é‡‡é›†ï¼ˆæ–‡æœ¬ã€è¯­éŸ³ã€é¢éƒ¨ã€è¡Œä¸ºï¼‰
- å»ºç«‹ç»†ç²’åº¦æƒ…æ„Ÿåˆ†ç±»æ¨¡å‹ï¼ˆå…­åŸºæœ¬æƒ…ç»ª+å¤åˆæƒ…ç»ªï¼‰
- æ„å»ºæƒ…æ„Ÿä¸Šä¸‹æ–‡æ¨¡å‹ï¼Œæ•æ‰æƒ…æ„ŸçŠ¶æ€è½¬ç§»
æƒ…æ„Ÿå…±æƒ…ï¼š
- è®¾è®¡æƒ…æ„Ÿ-å“åº”æ˜ å°„è§„åˆ™åº“
- å»ºç«‹ä¸ªæ€§åŒ–æƒ…æ„Ÿæ¨¡å‹ï¼Œé€‚åº”ç”¨æˆ·ç‰¹è´¨
- å®ç°æƒ…å¢ƒæ„ŸçŸ¥æœºåˆ¶ï¼Œç»“åˆä»»åŠ¡ä¸ç¯å¢ƒå› ç´ 
æƒ…æ„Ÿè¿›åŒ–ï¼š
- å¼•å…¥å¼ºåŒ–å­¦ä¹ æœºåˆ¶ï¼Œé€šè¿‡ç”¨æˆ·åé¦ˆä¼˜åŒ–å“åº”
- å®ç°è¿ç§»å­¦ä¹ ï¼Œä»ç¾¤ä½“åˆ°ä¸ªä½“çš„é€‚åº”
- æ„å»ºæŒç»­å­¦ä¹ ç³»ç»Ÿï¼Œéšæ—¶é—´æ¼”è¿›
#### 3.2 å¤šæ¨¡æ€èåˆå®ç°
æ•°æ®å±‚èåˆï¼š
- ç‰¹å¾çº§èåˆï¼šæå–å„æ¨¡æ€ç‰¹å¾ï¼Œè¿›è¡Œæ—©æœŸèåˆ
- å†³ç­–çº§èåˆï¼šå„æ¨¡æ€ç‹¬ç«‹åˆ†æï¼Œç»“æœè¿›è¡ŒåæœŸèåˆ
- æ··åˆèåˆï¼šç»“åˆç‰¹å¾çº§å’Œå†³ç­–çº§èåˆç­–ç•¥
æ¨¡å‹å±‚èåˆï¼š
- è·¨æ¨¡æ€åµŒå…¥å­¦ä¹ ï¼šå­¦ä¹ ä¸åŒæ¨¡æ€é—´çš„å…±äº«è¡¨ç¤ºç©ºé—´
- æ³¨æ„åŠ›æœºåˆ¶ï¼šåŠ¨æ€è°ƒæ•´ä¸åŒæ¨¡æ€çš„æƒé‡
- å¤šä»»åŠ¡å­¦ä¹ ï¼šåŒæ—¶ä¼˜åŒ–å¤šä¸ªç›¸å…³ä»»åŠ¡
åº”ç”¨å±‚èåˆï¼š
- å¤šæ¨¡æ€å¯¹è¯ç³»ç»Ÿï¼šç»“åˆæ–‡æœ¬ã€è¯­éŸ³ã€è§†è§‰è¿›è¡Œè‡ªç„¶äº¤äº’
- æƒ…æ„ŸåŒ–å¯è§†åŒ–ï¼šæ ¹æ®æƒ…æ„ŸçŠ¶æ€è°ƒæ•´è§†è§‰å‘ˆç°
- å¤šæ„Ÿå®˜åé¦ˆï¼šè§†è§‰ã€å¬è§‰ã€è§¦è§‰ååŒåé¦ˆ
---
# äºŒã€æƒ…æ„Ÿé©±åŠ¨å¯è§†åŒ–åŠŸèƒ½å‰ç«¯å®ç°æ–¹æ¡ˆ
## 1. ç”¨æˆ·æƒ…æ„Ÿçš„å®æ—¶æ•æ‰
### 1.1 æ–‡æœ¬æƒ…æ„Ÿæ•æ‰
```typescript
// æ–‡æœ¬æƒ…æ„Ÿæ•æ‰å®ç°
export class TextEmotionDetector {
  private socket: Socket;
  
  constructor() {
    this.socket = io('ws://emotion-api-server');
    this.setupListeners();
  }
  
  private setupListeners() {
    this.socket.on('text-emotion-result', (result: EmotionResult) => {
      EmotionStateStore.update(result);
    });
  }
  
  public detectTextEmotion(text: string) {
    this.socket.emit('analyze-text-emotion', { text, timestamp: Date.now() });
  }
}

```
### 1.2 è¯­éŸ³æƒ…æ„Ÿæ•æ‰
```typescript
// è¯­éŸ³æƒ…æ„Ÿæ•æ‰å®ç°
export class VoiceEmotionDetector {
  private audioContext: AudioContext;
  private mediaRecorder: MediaRecorder | null = null;
  private audioChunks: Blob[] = [];
  
  constructor() {
    this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
  }
  
  public async startRecording() {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      this.mediaRecorder = new MediaRecorder(stream);
      this.audioChunks = [];
      
      this.mediaRecorder.ondataavailable = (event) => {
        this.audioChunks.push(event.data);
      };
      
      this.mediaRecorder.onstop = () => {
        const audioBlob = new Blob(this.audioChunks, { type: 'audio/wav' });
        this.analyzeEmotion(audioBlob);
      };
      
      this.mediaRecorder.start();
    } catch (error) {
      console.error('Error accessing microphone:', error);
    }
  }
  
  public stopRecording() {
    if (this.mediaRecorder && this.mediaRecorder.state !== 'inactive') {
      this.mediaRecorder.stop();
    }
  }
  
  private analyzeEmotion(audioBlob: Blob) {
    // å®æ—¶æå–éŸ³é¢‘ç‰¹å¾
    const audioFeatures = this.extractAudioFeatures(audioBlob);
    
    // å‘é€åˆ°åç«¯è¿›è¡Œæƒ…æ„Ÿåˆ†æ
    EmotionAPI.analyzeVoiceEmotion(audioBlob, audioFeatures)
      .then(result => EmotionStateStore.update(result));
  }
  
  private extractAudioFeatures(audioBlob: Blob): AudioFeatures {
    // ä½¿ç”¨Web Audio APIæå–éŸ³è°ƒã€éŸ³é‡ã€è¯­é€Ÿç­‰ç‰¹å¾
    // å®ç°ç»†èŠ‚ç•¥...
    return { pitch: 0, volume: 0, tempo: 0, timbre: [] };
  }
}

```
### 1.3 è§†è§‰æƒ…æ„Ÿæ•æ‰
```typescript
// è§†è§‰æƒ…æ„Ÿæ•æ‰å®ç°
export class VisualEmotionDetector {
  private videoElement: HTMLVideoElement;
  private faceDetectionModel: faceDetection.FaceDetector;
  private isRunning: boolean = false;
  
  constructor(videoElement: HTMLVideoElement) {
    this.videoElement = videoElement;
    this.initializeModel();
  }
  
  private async initializeModel() {
    // åŠ è½½TensorFlow.jsé¢éƒ¨æ£€æµ‹æ¨¡å‹
    this.faceDetectionModel = await faceDetection.createDetector(
      faceDetection.SupportedModels.MediaPipeFaceDetector,
      {
        runtime: 'tfjs',
        refineLandmarks: true,
      }
    );
  }
  
  public async startDetection() {
    if (this.isRunning) return;
    
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      this.videoElement.srcObject = stream;
      this.isRunning = true;
      
      // å¼€å§‹å®æ—¶æ£€æµ‹
      this.detectEmotions();
    } catch (error) {
      console.error('Error accessing camera:', error);
    }
  }
  
  public stopDetection() {
    this.isRunning = false;
    if (this.videoElement.srcObject) {
      const tracks = (this.videoElement.srcObject as MediaStream).getTracks();
      tracks.forEach(track => track.stop());
    }
  }
  
  private async detectEmotions() {
    if (!this.isRunning) return;
    
    try {
      // æ£€æµ‹é¢éƒ¨
      const faces = await this.faceDetectionModel.estimateFaces(this.videoElement);
      
      if (faces.length > 0) {
        // æå–é¢éƒ¨è¡¨æƒ…ç‰¹å¾
        const facialFeatures = this.extractFacialFeatures(faces[0]);
        
        // åˆ†ææƒ…æ„Ÿ
        const emotionResult = await this.analyzeFacialEmotion(facialFeatures);
        
        // æ›´æ–°æƒ…æ„ŸçŠ¶æ€
        EmotionStateStore.update(emotionResult);
      }
    } catch (error) {
      console.error('Error in face detection:', error);
    }
    
    // ç»§ç»­ä¸‹ä¸€å¸§æ£€æµ‹
    requestAnimationFrame(() => this.detectEmotions());
  }
  
  private extractFacialFeatures(face: faceDetection.Face): FacialFeatures {
    // æå–å…³é”®é¢éƒ¨ç‰¹å¾ç‚¹ï¼Œå¦‚çœ‰æ¯›ã€çœ¼ç›ã€å˜´å·´çš„ä½ç½®å’Œå½¢çŠ¶
    // å®ç°ç»†èŠ‚ç•¥...
    return { 
      eyebrowPosition: 0,
      eyeOpenness: 0,
      mouthShape: '',
      cheekRaise: 0 
    };
  }
  
  private async analyzeFacialEmotion(features: FacialFeatures): Promise<EmotionResult> {
    // ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹åˆ†æé¢éƒ¨è¡¨æƒ…å¯¹åº”çš„æƒ…æ„Ÿ
    // å®ç°ç»†èŠ‚ç•¥...
    return {
      valence: 0,
      arousal: 0,
      primaryEmotion: 'neutral',
      confidence: 0.5
    };
  }
}

```
### 1.4 ç”¨æˆ·è¡Œä¸ºæ¨¡å¼æƒ…æ„Ÿæ¨æ–­
```typescript
// ç”¨æˆ·è¡Œä¸ºæƒ…æ„Ÿæ¨æ–­å®ç°
export class BehaviorEmotionDetector {
  private interactionData: InteractionData[] = [];
  private lastActivityTime: number = Date.now();
  
  constructor() {
    this.setupInteractionListeners();
  }
  
  private setupInteractionListeners() {
    // ç›‘å¬é¼ æ ‡ç§»åŠ¨
    document.addEventListener('mousemove', this.handleMouseMove.bind(this));
    
    // ç›‘å¬ç‚¹å‡»
    document.addEventListener('click', this.handleClick.bind(this));
    
    // ç›‘å¬æ»šåŠ¨
    document.addEventListener('scroll', this.handleScroll.bind(this));
    
    // ç›‘å¬é”®ç›˜è¾“å…¥
    document.addEventListener('keydown', this.handleKeyDown.bind(this));
  }
  
  private handleMouseMove(event: MouseEvent) {
    this.recordInteraction({
      type: 'mousemove',
      timestamp: Date.now(),
      x: event.clientX,
      y: event.clientY,
      velocity: this.calculateVelocity(event)
    });
  }
  
  private handleClick(event: MouseEvent) {
    this.recordInteraction({
      type: 'click',
      timestamp: Date.now(),
      x: event.clientX,
      y: event.clientY,
      target: event.target
    });
  }
  
  private handleScroll(event: Event) {
    this.recordInteraction({
      type: 'scroll',
      timestamp: Date.now(),
      scrollY: window.scrollY,
      velocity: this.calculateScrollVelocity()
    });
  }
  
  private handleKeyDown(event: KeyboardEvent) {
    this.recordInteraction({
      type: 'keydown',
      timestamp: Date.now(),
      key: event.key,
      inputType: this.getInputType(event)
    });
  }
  
  private recordInteraction(data: InteractionData) {
    this.interactionData.push(data);
    
    // ä¿æŒæ•°æ®é‡åœ¨åˆç†èŒƒå›´
    if (this.interactionData.length > 100) {
      this.interactionData.shift();
    }
    
    // å®šæœŸåˆ†æè¡Œä¸ºæ¨¡å¼
    if (Date.now() - this.lastActivityTime > 2000) {
      this.analyzeBehaviorPattern();
      this.lastActivityTime = Date.now();
    }
  }
  
  private calculateVelocity(event: MouseEvent): number {
    // è®¡ç®—é¼ æ ‡ç§»åŠ¨é€Ÿåº¦
    // å®ç°ç»†èŠ‚ç•¥...
    return 0;
  }
  
  private calculateScrollVelocity(): number {
    // è®¡ç®—æ»šåŠ¨é€Ÿåº¦
    // å®ç°ç»†èŠ‚ç•¥...
    return 0;
  }
  
  private getInputType(event: KeyboardEvent): string {
    // åˆ¤æ–­è¾“å…¥ç±»å‹ï¼ˆå¦‚åˆ é™¤ã€è¾“å…¥ã€å¯¼èˆªç­‰ï¼‰
    // å®ç°ç»†èŠ‚ç•¥...
    return 'input';
  }
  
  private async analyzeBehaviorPattern() {
    if (this.interactionData.length < 5) return;
    
    // æå–è¡Œä¸ºç‰¹å¾
    const behaviorFeatures = this.extractBehaviorFeatures();
    
    // å‘é€åˆ°åç«¯åˆ†ææˆ–ä½¿ç”¨æœ¬åœ°æ¨¡å‹
    const emotionResult = await EmotionAPI.analyzeBehaviorEmotion(behaviorFeatures);
    
    // æ›´æ–°æƒ…æ„ŸçŠ¶æ€
    EmotionStateStore.update(emotionResult);
  }
  
  private extractBehaviorFeatures(): BehaviorFeatures {
    // æå–è¡Œä¸ºæ¨¡å¼ç‰¹å¾ï¼Œå¦‚ç‚¹å‡»é¢‘ç‡ã€ç§»åŠ¨é€Ÿåº¦ã€è¾“å…¥èŠ‚å¥ç­‰
    // å®ç°ç»†èŠ‚ç•¥...
    return {
      clickFrequency: 0,
      mouseSpeed: 0,
      scrollIntensity: 0,
      typingRhythm: 0,
      navigationPattern: ''
    };
  }
}

```
## 2. å‰ç«¯åŠ¨æ€å“åº”æœºåˆ¶è®¾è®¡
### 2.1 æƒ…æ„ŸçŠ¶æ€åˆ°UIå‚æ•°çš„æ˜ å°„
```typescript
// æƒ…æ„Ÿåˆ°UIå‚æ•°çš„æ˜ å°„å·¥å…·
export class EmotionToUIMapper {
  // å°†æƒ…æ„ŸçŠ¶æ€æ˜ å°„ä¸ºé¢œè‰²
  static mapToColor(emotion: EmotionState): string {
    const { valence, arousal } = emotion;
    
    // åŸºäºæ•ˆä»·-å”¤é†’åº¦æ¨¡å‹çš„HSLé¢œè‰²æ˜ å°„
    let hue: number;
    if (valence > 0) {
      // æ­£æ•ˆä»·ï¼šæš–è‰²è°ƒ (é»„-æ©™-çº¢)
      hue = 30 + (1 - valence) * 30; // 30-60åº¦
    } else {
      // è´Ÿæ•ˆä»·ï¼šå†·è‰²è°ƒ (è“-ç´«)
      hue = 240 + valence * 60; // 180-240åº¦
    }
    
    // å”¤é†’åº¦å½±å“é¥±å’Œåº¦
    const saturation = 50 + Math.abs(arousal) * 50; // 50-100%
    
    // æ•ˆä»·å½±å“äº®åº¦
    const lightness = 40 + valence * 20 + (1 - Math.abs(arousal)) * 10; // 30-70%
    
    return `hsl(${hue}, ${saturation}%, ${lightness}%)`;
  }
  
  // å°†æƒ…æ„ŸçŠ¶æ€æ˜ å°„ä¸ºåŠ¨ç”»å‚æ•°
  static mapToAnimation(emotion: EmotionState): AnimationParams {
    const { valence, arousal } = emotion;
    
    return {
      // å”¤é†’åº¦å½±å“åŠ¨ç”»é€Ÿåº¦
      duration: 1.5 - Math.abs(arousal) * 1.0, // 0.5-1.5ç§’
      
      // æ•ˆä»·å½±å“ç¼“åŠ¨å‡½æ•°ç±»å‹
      easing: valence > 0 
        ? 'cubic-bezier(0.34, 1.56, 0.64, 1)' // å¼¹æ€§æ•ˆæœ
        : 'cubic-bezier(0.55, 0.055, 0.675, 0.19)', // å¹³æ»‘æ•ˆæœ
      
      // å”¤é†’åº¦å½±å“åŠ¨ç”»å¹…åº¦
      amplitude: 5 + Math.abs(arousal) * 15, // 5-20åƒç´ 
      
      // æ•ˆä»·å½±å“åŠ¨ç”»æ–¹å‘
      direction: valence > 0 ? 'upward' : 'downward'
    };
  }
  
  // å°†æƒ…æ„ŸçŠ¶æ€æ˜ å°„ä¸ºå¸ƒå±€å‚æ•°
  static mapToLayout(emotion: EmotionState): LayoutParams {
    const { valence, arousal } = emotion;
    
    return {
      // å”¤é†’åº¦å½±å“å…ƒç´ é—´è·
      spacing: 8 + Math.abs(arousal) * 12, // 8-20åƒç´ 
      
      // æ•ˆä»·å½±å“å…ƒç´ æ’åˆ—
      arrangement: valence > 0 ? 'expansive' : 'compact',
      
      // å”¤é†’åº¦å½±å“å±‚æ¬¡æ„Ÿ
      depth: Math.abs(arousal) * 10, // 0-10åƒç´ 
      
      // æ•ˆä»·å½±å“è§†è§‰é‡é‡åˆ†å¸ƒ
      balance: valence > 0 ? 'light' : 'heavy'
    };
  }
  
  // å°†æƒ…æ„ŸçŠ¶æ€æ˜ å°„ä¸ºéŸ³æ•ˆå‚æ•°
  static mapToSound(emotion: EmotionState): SoundParams {
    const { valence, arousal } = emotion;
    
    return {
      // æ•ˆä»·å½±å“éŸ³é«˜
      frequency: 220 + valence * 110, // 110-330Hz
      
      // å”¤é†’åº¦å½±å“éŸ³é‡
      volume: 0.1 + Math.abs(arousal) * 0.2, // 0.1-0.3
      
      // æ•ˆä»·å½±å“éŸ³è‰²
      timbre: valence > 0 ? 'sine' : 'triangle',
      
      // å”¤é†’åº¦å½±å“éŸ³æ•ˆèŠ‚å¥
      tempo: 60 + Math.abs(arousal) * 120 // 60-180BPM
    };
  }
}

```
### 2.2 æƒ…æ„ŸçŠ¶æ€è¿‡æ¸¡æœºåˆ¶
```typescript
// æƒ…æ„ŸçŠ¶æ€å¹³æ»‘è¿‡æ¸¡ç®¡ç†å™¨
export class EmotionTransitionManager {
  private currentEmotion: EmotionState;
  private targetEmotion: EmotionState;
  private transitionProgress: number = 1;
  private transitionSpeed: number = 0.1;
  private isTransitioning: boolean = false;
  private callbacks: ((emotion: EmotionState) => void)[] = [];
  
  constructor(initialEmotion: EmotionState) {
    this.currentEmotion = { ...initialEmotion };
    this.targetEmotion = { ...initialEmotion };
  }
  
  // è®¾ç½®æ–°çš„ç›®æ ‡æƒ…æ„ŸçŠ¶æ€
  public setTargetEmotion(newEmotion: EmotionState) {
    this.targetEmotion = { ...newEmotion };
    this.transitionProgress = 0;
    this.isTransitioning = true;
    
    // å¼€å§‹è¿‡æ¸¡åŠ¨ç”»
    this.startTransition();
  }
  
  // æ³¨å†Œæƒ…æ„ŸçŠ¶æ€å˜åŒ–å›è°ƒ
  public onEmotionChange(callback: (emotion: EmotionState) => void) {
    this.callbacks.push(callback);
  }
  
  // å¼€å§‹è¿‡æ¸¡åŠ¨ç”»
  private startTransition() {
    if (!this.isTransitioning) return;
    
    // æ›´æ–°è¿‡æ¸¡è¿›åº¦
    this.transitionProgress += this.transitionSpeed;
    
    // æ£€æŸ¥æ˜¯å¦å®Œæˆè¿‡æ¸¡
    if (this.transitionProgress >= 1) {
      this.transitionProgress = 1;
      this.currentEmotion = { ...this.targetEmotion };
      this.isTransitioning = false;
    } else {
      // è®¡ç®—å½“å‰æƒ…æ„ŸçŠ¶æ€ï¼ˆæ’å€¼ï¼‰
      this.currentEmotion = this.interpolateEmotion(
        this.currentEmotion,
        this.targetEmotion,
        this.easeInOutCubic(this.transitionProgress)
      );
      
      // ç»§ç»­è¿‡æ¸¡
      requestAnimationFrame(() => this.startTransition());
    }
    
    // é€šçŸ¥æ‰€æœ‰å›è°ƒ
    this.notifyCallbacks();
  }
  
  // æƒ…æ„ŸçŠ¶æ€æ’å€¼
  private interpolateEmotion(
    start: EmotionState, 
    end: EmotionState, 
    progress: number
  ): EmotionState {
    return {
      valence: start.valence + (end.valence - start.valence) * progress,
      arousal: start.arousal + (end.arousal - start.arousal) * progress,
      primaryEmotion: progress > 0.5 ? end.primaryEmotion : start.primaryEmotion,
      confidence: start.confidence + (end.confidence - start.confidence) * progress
    };
  }
  
  // ç¼“åŠ¨å‡½æ•°
  private easeInOutCubic(t: number): number {
    return t < 0.5 
      ? 4 * t * t * t 
      : 1 - Math.pow(-2 * t + 2, 3) / 2;
  }
  
  // é€šçŸ¥æ‰€æœ‰å›è°ƒ
  private notifyCallbacks() {
    const emotionCopy = { ...this.currentEmotion };
    this.callbacks.forEach(callback => callback(emotionCopy));
  }
  
  // è·å–å½“å‰æƒ…æ„ŸçŠ¶æ€
  public getCurrentEmotion(): EmotionState {
    return { ...this.currentEmotion };
  }
}

```
### 2.3 æƒ…æ„Ÿåé¦ˆæœºåˆ¶
```typescript
// æƒ…æ„ŸåŒ–åé¦ˆç»„ä»¶
export const EmotionFeedback: React.FC<{ emotion: EmotionState }> = ({ emotion }) => {
  const [visible, setVisible] = useState(false);
  const [feedbackType, setFeedbackType] = useState<'emoji' | 'message' | 'particles'>('emoji');
  
  useEffect(() => {
    // æ ¹æ®æƒ…æ„Ÿå¼ºåº¦å†³å®šæ˜¯å¦æ˜¾ç¤ºåé¦ˆ
    const intensity = Math.sqrt(emotion.valence ** 2 + emotion.arousal ** 2);
    setVisible(intensity > 0.5);
    
    // æ ¹æ®æƒ…æ„Ÿç±»å‹é€‰æ‹©åé¦ˆå½¢å¼
    if (emotion.arousal > 0.7) {
      setFeedbackType('particles');
    } else if (Math.abs(emotion.valence) > 0.6) {
      setFeedbackType('emoji');
    } else {
      setFeedbackType('message');
    }
  }, [emotion]);
  
  if (!visible) return null;
  
  return (
    <motion.div
      className="emotion-feedback"
      initial={{ opacity: 0, scale: 0.8 }}
      animate={{ opacity: 1, scale: 1 }}
      exit={{ opacity: 0, scale: 0.8 }}
      transition={{ duration: 0.5 }}
    >
      {feedbackType === 'emoji' && <EmotionEmoji emotion={emotion} />}
      {feedbackType === 'message' && <EmotionMessage emotion={emotion} />}
      {feedbackType === 'particles' && <EmotionParticles emotion={emotion} />}
    </motion.div>
  );
};

// æƒ…æ„ŸåŒ–è¡¨æƒ…ç»„ä»¶
const EmotionEmoji: React.FC<{ emotion: EmotionState }> = ({ emotion }) => {
  // æ ¹æ®æƒ…æ„ŸçŠ¶æ€é€‰æ‹©è¡¨æƒ…
  const getEmoji = (): string => {
    if (emotion.valence > 0.5) return 'ğŸ˜„';
    if (emotion.valence > 0.2) return 'ğŸ™‚';
    if (emotion.valence > -0.2) return 'ğŸ˜';
    if (emotion.valence > -0.5) return 'ğŸ˜”';
    return 'ğŸ˜¢';
  };
  
  return (
    <motion.div
      className="emotion-emoji"
      animate={{
        scale: [1, 1.2, 1],
        rotate: emotion.arousal > 0 ? [0, 10, -10, 0] : [0, 0, 0, 0]
      }}
      transition={{ duration: 1.5 }}
    >
      {getEmoji()}
    </motion.div>
  );
};

// æƒ…æ„ŸåŒ–æ¶ˆæ¯ç»„ä»¶
const EmotionMessage: React.FC<{ emotion: EmotionState }> = ({ emotion }) => {
  // æ ¹æ®æƒ…æ„ŸçŠ¶æ€ç”Ÿæˆæ¶ˆæ¯
  const getMessage = (): string => {
    if (emotion.valence > 0.5) return 'çœ‹èµ·æ¥æ‚¨å¿ƒæƒ…å¾ˆå¥½ï¼';
    if (emotion.valence > 0.2) return 'æ‚¨ä¼¼ä¹æ„Ÿåˆ°æ„‰å¿«ã€‚';
    if (emotion.valence > -0.2) return 'æ‚¨æ„Ÿè§‰å¹³é™ã€‚';
    if (emotion.valence > -0.5) return 'æ‚¨ä¼¼ä¹æœ‰äº›ä½è½ã€‚';
    return 'æ‚¨çœ‹èµ·æ¥å¾ˆéš¾è¿‡ï¼Œå¸Œæœ›æƒ…å†µèƒ½å¥½è½¬ã€‚';
  };
  
  return (
    <motion.div
      className="emotion-message"
      initial={{ y: 20 }}
      animate={{ y: 0 }}
      transition={{ type: 'spring', damping: 10 }}
    >
      {getMessage()}
    </motion.div>
  );
};

// æƒ…æ„ŸåŒ–ç²’å­æ•ˆæœç»„ä»¶
const EmotionParticles: React.FC<{ emotion: EmotionState }> = ({ emotion }) => {
  const canvasRef = useRef<HTMLCanvasElement>(null);
  
  useEffect(() => {
    const canvas = canvasRef.current;
    if (!canvas) return;
    
    const ctx = canvas.getContext('2d');
    if (!ctx) return;
    
    // åˆ›å»ºç²’å­ç³»ç»Ÿ
    const particleSystem = new ParticleSystem(canvas, {
      count: Math.floor(30 + Math.abs(emotion.arousal) * 50),
      color: EmotionToUIMapper.mapToColor(emotion),
      speed: Math.abs(emotion.arousal) * 3,
      size: 2 + Math.abs(emotion.valence) * 3,
      spread: emotion.valence > 0 ? 'upward' : 'downward',
    });
    
    // åŠ¨ç”»å¾ªç¯
    let animationFrameId: number;
    const render = () => {
      particleSystem.update();
      particleSystem.render(ctx);
      animationFrameId = requestAnimationFrame(render);
    };
    
    render();
    
    return () => {
      cancelAnimationFrame(animationFrameId);
    };
  }, [emotion]);
  
  return <canvas ref={canvasRef} className="emotion-particles" width={300} height={200} />;
};

```
## 3. å‰ç«¯æŠ€æœ¯æ ˆå»ºè®®
- æ ¸å¿ƒæ¡†æ¶ï¼šReact 18+ (ä½¿ç”¨Next.jså®ç°SSR/SSG)
- çŠ¶æ€ç®¡ç†ï¼šRedux Toolkit (å…¨å±€çŠ¶æ€) + Zustand (å±€éƒ¨çŠ¶æ€)
- UIåº“ï¼šMaterial-UI (MUI) / è‡ªç ”è®¾è®¡ç³»ç»Ÿ
- åŠ¨ç”»åº“ï¼šFramer Motion (UIåŠ¨ç”») + GSAP (å¤æ‚åŠ¨ç”»)
- CSSè§£å†³æ–¹æ¡ˆï¼šStyled Components / Emotion (CSS-in-JS)
- éŸ³è§†é¢‘å¤„ç†ï¼šWeb Audio API, MediaRecorder API
- AIå‰ç«¯æ¨ç†ï¼šTensorFlow.js, ONNX Runtime Web
- å®æ—¶é€šä¿¡ï¼šWebSocket (Socket.io)
- å›¾è¡¨å¯è§†åŒ–ï¼šD3.js / ECharts
- 3Dæ¸²æŸ“ï¼šThree.js
## 4. å®Œæ•´ä»£ç ç»“æ„ç¤ºä¾‹
```typescript
// types/index.ts
export interface EmotionState {
  valence: number; // [-1, 1], è´Ÿåˆ°æ­£
  arousal: number; // [-1, 1], å¹³é™åˆ°å…´å¥‹
  primaryEmotion: string; // ä¸»è¦æƒ…ç»ªç±»åˆ«
  confidence: number; // [0, 1], ç½®ä¿¡åº¦
}

export interface AnimationParams {
  duration: number;
  easing: string;
  amplitude: number;
  direction: 'upward' | 'downward';
}

export interface LayoutParams {
  spacing: number;
  arrangement: 'expansive' | 'compact';
  depth: number;
  balance: 'light' | 'heavy';
}

export interface SoundParams {
  frequency: number;
  volume: number;
  timbre: string;
  tempo: number;
}

// stores/emotionStore.ts
export const useEmotionStore = create<EmotionState>((set) => ({
  valence: 0,
  arousal: 0,
  primaryEmotion: 'neutral',
  confidence: 0.5,
  update: (newEmotion: Partial<EmotionState>) => set((state) => ({ ...state, ...newEmotion }))
}));

// hooks/useEmotionDetection.ts
export const useEmotionDetection = () => {
  const emotion = useEmotionStore();
  const textDetector = useRef(new TextEmotionDetector());
  const voiceDetector = useRef(new VoiceEmotionDetector());
  const visualDetector = useRef<VisualEmotionDetector | null>(null);
  const behaviorDetector = useRef(new BehaviorEmotionDetector());
  
  // åˆå§‹åŒ–è§†è§‰æ£€æµ‹å™¨
  const initVisualDetection = (videoElement: HTMLVideoElement) => {
    visualDetector.current = new VisualEmotionDetector(videoElement);
  };
  
  // åˆ†ææ–‡æœ¬æƒ…æ„Ÿ
  const analyzeTextEmotion = (text: string) => {
    textDetector.current.detectTextEmotion(text);
  };
  
  // å¼€å§‹è¯­éŸ³æƒ…æ„Ÿåˆ†æ
  const startVoiceAnalysis = () => {
    voiceDetector.current.startRecording();
  };
  
  // åœæ­¢è¯­éŸ³æƒ…æ„Ÿåˆ†æ
  const stopVoiceAnalysis = () => {
    voiceDetector.current.stopRecording();
  };
  
  // å¼€å§‹è§†è§‰æƒ…æ„Ÿåˆ†æ
  const startVisualAnalysis = () => {
    if (visualDetector.current) {
      visualDetector.current.startDetection();
    }
  };
  
  // åœæ­¢è§†è§‰æƒ…æ„Ÿåˆ†æ
  const stopVisualAnalysis = () => {
    if (visualDetector.current) {
      visualDetector.current.stopDetection();
    }
  };
  
  return {
    emotion,
    analyzeTextEmotion,
    startVoiceAnalysis,
    stopVoiceAnalysis,
    initVisualDetection,
    startVisualAnalysis,
    stopVisualAnalysis
  };
};

// components/EmotionThemeProvider.tsx
export const EmotionThemeProvider: React.FC<{ children: React.ReactNode }> = ({ children }) => {
  const emotion = useEmotionStore();
  
  // æ ¹æ®æƒ…æ„ŸçŠ¶æ€åˆ›å»ºä¸»é¢˜
  const theme = useMemo(() => {
    const { valence, arousal } = emotion;
    const primaryColor = EmotionToUIMapper.mapToColor(emotion);
    const animationParams = EmotionToUIMapper.mapToAnimation(emotion);
    const layoutParams = EmotionToUIMapper.mapToLayout(emotion);
    
    return createTheme({
      palette: {
        mode: valence > 0 ? 'light' : 'dark',
        primary: {
          main: primaryColor,
        },
        background: {
          default: valence > 0 ? lighten(primaryColor, 0.9) : darken(primaryColor, 0.8),
        },
      },
      spacing: layoutParams.spacing,
      transitions: {
        duration: {
          standard: animationParams.duration * 1000,
        },
        easing: {
          easeInOut: animationParams.easing,
        },
      },
      shape: {
        borderRadius: 8,
      },
      zIndex: {
        appBar: 1200,
        drawer: 1100,
        modal: 1300,
        tooltip: 1500,
      },
    });
  }, [emotion]);
  
  return (
    <ThemeProvider theme={theme}>
      <CssBaseline />
      <GlobalStyles styles={{
        body: {
          transition: 'background-color 1s ease',
        },
      }} />
      {children}
    </ThemeProvider>
  );
};

// components/EmotionVisualizationContainer.tsx
export const EmotionVisualizationContainer: React.FC = () => {
  const { emotion } = useEmotionDetection();
  const animationParams = EmotionToUIMapper.mapToAnimation(emotion);
  const layoutParams = EmotionToUIMapper.mapToLayout(emotion);
  
  return (
    <motion.div
      className="emotion-visualization-container"
      animate={{
        scale: 1 + emotion.arousal * 0.05,
        y: emotion.valence * 10,
      }}
      transition={{
        duration: animationParams.duration,
        ease: animationParams.easing,
      }}
      style={{
        padding: layoutParams.spacing,
        gap: layoutParams.spacing,
      }}
    >
      {/* æƒ…æ„ŸåŒ–å¯è§†åŒ–å†…å®¹ */}
      <EmotionVisualization />
      
      {/* æƒ…æ„Ÿåé¦ˆ */}
      <EmotionFeedback emotion={emotion} />
      
      {/* æƒ…æ„ŸåŒ–éŸ³æ•ˆ */}
      <EmotionSound emotion={emotion} />
    </motion.div>
  );
};

// components/EmotionVisualization.tsx
export const EmotionVisualization: React.FC = () => {
  const { emotion } = useEmotionDetection();
  const color = EmotionToUIMapper.mapToColor(emotion);
  const animationParams = EmotionToUIMapper.mapToAnimation(emotion);
  
  // ç”Ÿæˆæƒ…æ„ŸåŒ–å›¾è¡¨æ•°æ®
  const chartData = useMemo(() => {
    return generateEmotionChartData(emotion);
  }, [emotion]);
  
  return (
    <motion.div
      className="emotion-visualization"
      initial={{ opacity: 0 }}
      animate={{ opacity: 1 }}
      transition={{ duration: animationParams.duration }}
    >
      <h2 style={{ color }}>æƒ…æ„ŸåŒ–æ•°æ®å¯è§†åŒ–</h2>
      
      <motion.div
        className="chart-container"
        animate={{
          backgroundColor: color + '20', // æ·»åŠ é€æ˜åº¦
          borderColor: color,
        }}
        transition={{ duration: animationParams.duration }}
      >
        <ResponsiveContainer width="100%" height={300}>
          <AreaChart data={chartData}>
            <defs>
              <linearGradient id="colorEmotion" x1="0" y1="0" x2="0" y2="1">
                <stop offset="5%" stopColor={color} stopOpacity={0.8}/>
                <stop offset="95%" stopColor={color} stopOpacity={0.1}/>
              </linearGradient>
            </defs>
            <XAxis dataKey="name" />
            <YAxis />
            <CartesianGrid strokeDasharray="3 3" />
            <Tooltip />
            <Area 
              type="monotone" 
              dataKey="value" 
              stroke={color} 
              fillOpacity={1} 
              fill="url(#colorEmotion)" 
              animationDuration={animationParams.duration * 1000}
            />
          </AreaChart>
        </ResponsiveContainer>
      </motion.div>
      
      <motion.div
        className="emotion-metrics"
        layout
        transition={{ duration: animationParams.duration }}
      >
        <div className="metric">
          <span className="label">æ•ˆä»·</span>
          <span className="value" style={{ color }}>
            {emotion.valence.toFixed(2)}
          </span>
        </div>
        <div className="metric">
          <span className="label">å”¤é†’åº¦</span>
          <span className="value" style={{ color }}>
            {emotion.arousal.toFixed(2)}
          </span>
        </div>
        <div className="metric">
          <span className="label">ä¸»è¦æƒ…ç»ª</span>
          <span className="value" style={{ color }}>
            {emotion.primaryEmotion}
          </span>
        </div>
      </motion.div>
    </motion.div>
  );
};

// components/EmotionSound.tsx
export const EmotionSound: React.FC<{ emotion: EmotionState }> = ({ emotion }) => {
  const audioContextRef = useRef<AudioContext | null>(null);
  const oscillatorRef = useRef<OscillatorNode | null>(null);
  const gainNodeRef = useRef<GainNode | null>(null);
  
  useEffect(() => {
    // åˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡
    audioContextRef.current = new (window.AudioContext || (window as any).webkitAudioContext)();
    
    return () => {
      oscillatorRef.current?.stop();
      audioContextRef.current?.close();
    };
  }, []);
  
  useEffect(() => {
    if (!audioContextRef.current) return;
    
    // åœæ­¢ä¹‹å‰çš„éŸ³è°ƒ
    if (oscillatorRef.current) {
      oscillatorRef.current.stop();
    }
    
    // è·å–éŸ³æ•ˆå‚æ•°
    const soundParams = EmotionToUIMapper.mapToSound(emotion);
    
    // åˆ›å»ºæ–°çš„æŒ¯è¡å™¨
    oscillatorRef.current = audioContextRef.current.createOscillator();
    gainNodeRef.current = audioContextRef.current.createGain();
    
    // è®¾ç½®éŸ³é¢‘å‚æ•°
    oscillatorRef.current.type = soundParams.timbre as OscillatorType;
    oscillatorRef.current.frequency.setValueAtTime(
      soundParams.frequency, 
      audioContextRef.current.currentTime
    );
    
    if (gainNodeRef.current) {
      gainNodeRef.current.gain.setValueAtTime(
        soundParams.volume, 
        audioContextRef.current.currentTime
      );
    }
    
    // è¿æ¥èŠ‚ç‚¹
    oscillatorRef.current.connect(gainNodeRef.current);
    gainNodeRef.current.connect(audioContextRef.current.destination);
    
    // æ’­æ”¾éŸ³è°ƒ
    oscillatorRef.current.start();
    
    // æ·»åŠ éŸ³é‡åŒ…ç»œ
    const now = audioContextRef.current.currentTime;
    if (gainNodeRef.current) {
      gainNodeRef.current.gain.setValueAtTime(0, now);
      gainNodeRef.current.gain.linearRampToValueAtTime(soundParams.volume, now + 0.1);
      gainNodeRef.current.gain.linearRampToValueAtTime(0, now + 1);
    }
    
    // 1ç§’ååœæ­¢
    setTimeout(() => {
      if (oscillatorRef.current) {
        oscillatorRef.current.stop();
        oscillatorRef.current = null;
      }
    }, 1000);
  }, [emotion]);
  
  return null; // è¿™ä¸ªç»„ä»¶ä¸æ¸²æŸ“ä»»ä½•UI
};

// pages/EmotionVisualizationPage.tsx
export const EmotionVisualizationPage: React.FC = () => {
  const { 
    emotion, 
    analyzeTextEmotion, 
    startVoiceAnalysis, 
    stopVoiceAnalysis,
    initVisualDetection,
    startVisualAnalysis,
    stopVisualAnalysis
  } = useEmotionDetection();
  
  const [inputText, setInputText] = useState('');
  const [isRecording, setIsRecording] = useState(false);
  const [isCameraActive, setIsCameraActive] = useState(false);
  const videoRef = useRef<HTMLVideoElement>(null);
  
  const handleTextSubmit = () => {
    if (inputText.trim()) {
      analyzeTextEmotion(inputText);
    }
  };
  
  const toggleVoiceRecording = () => {
    if (isRecording) {
      stopVoiceAnalysis();
    } else {
      startVoiceAnalysis();
    }
    setIsRecording(!isRecording);
  };
  
  const toggleCamera = () => {
    if (isCameraActive) {
      stopVisualAnalysis();
      setIsCameraActive(false);
    } else {
      if (videoRef.current) {
        initVisualDetection(videoRef.current);
        startVisualAnalysis();
        setIsCameraActive(true);
      }
    }
  };
  
  return (
    <EmotionThemeProvider>
      <div className="emotion-visualization-page">
        <header className="page-header">
          <h1>ä¸‡è±¡å½’å…ƒäºäº‘æ¢</h1>
          <p>æƒ…æ„ŸåŒ–æ™ºèƒ½å¯è§†åŒ–ç³»ç»Ÿ</p>
        </header>
        
        <main className="page-content">
          <div className="emotion-input-section">
            <div className="text-input">
              <TextField
                fullWidth
                label="è¾“å…¥æ–‡æœ¬ä»¥åˆ†ææƒ…æ„Ÿ"
                value={inputText}
                onChange={(e) => setInputText(e.target.value)}
                onKeyPress={(e) => e.key === 'Enter' && handleTextSubmit()}
                variant="outlined"
              />
              <Button 
                variant="contained" 
                onClick={handleTextSubmit}
                sx={{ mt: 2 }}
              >
                åˆ†ææƒ…æ„Ÿ
              </Button>
            </div>
            
            <div className="audio-input">
              <Button
                variant={isRecording ? "contained" : "outlined"}
                color={isRecording ? "secondary" : "primary"}
                startIcon={isRecording ? <MicOffIcon /> : <MicIcon />}
                onClick={toggleVoiceRecording}
              >
                {isRecording ? 'åœæ­¢å½•éŸ³' : 'å¼€å§‹å½•éŸ³'}
              </Button>
            </div>
            
            <div className="video-input">
              <Button
                variant={isCameraActive ? "contained" : "outlined"}
                color={isCameraActive ? "secondary" : "primary"}
                startIcon={isCameraActive ? <VideocamOffIcon /> : <VideocamIcon />}
                onClick={toggleCamera}
              >
                {isCameraActive ? 'å…³é—­æ‘„åƒå¤´' : 'å¼€å¯æ‘„åƒå¤´'}
              </Button>
              
              {isCameraActive && (
                <video 
                  ref={videoRef} 
                  autoPlay 
                  playsInline 
                  muted 
                  className="video-preview"
                />
              )}
            </div>
          </div>
          
          <div className="emotion-state-display">
            <h2>å½“å‰æƒ…æ„ŸçŠ¶æ€</h2>
            <div className="emotion-metrics">
              <div className="metric">
                <span className="label">æ•ˆä»·</span>
                <span className="value">{emotion.valence.toFixed(2)}</span>
              </div>
              <div className="metric">
                <span className="label">å”¤é†’åº¦</span>
                <span className="value">{emotion.arousal.toFixed(2)}</span>
              </div>
              <div className="metric">
                <span className="label">ä¸»è¦æƒ…ç»ª</span>
                <span className="value">{emotion.primaryEmotion}</span>
              </div>
              <div className="metric">
                <span className="label">ç½®ä¿¡åº¦</span>
                <span className="value">{(emotion.confidence * 100).toFixed(1)}%</span>
              </div>
            </div>
            
            <div className="emotion-visualization">
              <EmotionVisualizationContainer />
            </div>
          </div>
        </main>
      </div>
    </EmotionThemeProvider>
  );
};

```
## æ€»ç»“
æœ¬æ¶æ„ææ¡ˆä¸ºã€Œä¸‡è±¡å½’å…ƒäºäº‘æ¢ã€æƒ…æ„ŸåŒ–æ™ºèƒ½AIè®¾è®¡ç³»ç»Ÿæä¾›äº†å®Œæ•´çš„æŠ€æœ¯å®ç°æ–¹æ¡ˆã€‚ç³»ç»Ÿé€šè¿‡å¤šæ¨¡æ€èåˆæŠ€æœ¯å®ç°äº†æƒ…æ„Ÿæ„ŸçŸ¥ã€å…±æƒ…å’Œè¿›åŒ–èƒ½åŠ›ï¼Œå°†æ•°æ®ã€ä»£ç ã€åŠ¨ç”»ä¸éŸ³æ•ˆç¼–ç»‡æˆè¯—ï¼Œè®©æ¯æ¬¡äº¤äº’éƒ½æˆä¸ºå¿ƒçµä¸ç§‘æŠ€çš„æ¸©æŸ”å…±é¸£ã€‚
æƒ…æ„Ÿé©±åŠ¨å¯è§†åŒ–åŠŸèƒ½é€šè¿‡å®æ—¶æ•æ‰ç”¨æˆ·æƒ…ç»ªçš„ç»†å¾®å˜åŒ–ï¼Œå®ç°äº†ç•Œé¢ä¸ç”¨æˆ·æƒ…æ„Ÿçš„å…±èˆã€‚ç³»ç»Ÿåˆ©ç”¨NLPæŠ€æœ¯å’Œå¿ƒç†å­¦æ¨¡å‹åˆ†æç”¨æˆ·æƒ…ç»ªï¼Œå¹¶å°†æƒ…ç»ªçŠ¶æ€æ˜ å°„åˆ°ç•Œé¢çš„é¢œè‰²ã€åŠ¨ç”»ã€å¸ƒå±€å’ŒéŸ³æ•ˆç­‰å¤šä¸ªç»´åº¦ï¼Œåˆ›é€ å‡ºçœŸæ­£æƒ…æ„ŸåŒ–çš„äººæœºäº¤äº’ä½“éªŒã€‚
è¿™ä¸€æ¶æ„ä¸ä»…æ»¡è¶³äº†ç³»ç»Ÿå½“å‰çš„éœ€æ±‚ï¼Œè¿˜ä¸ºæœªæ¥çš„æ‰©å±•å’Œä¼˜åŒ–æä¾›äº†åšå®çš„åŸºç¡€ï¼Œä½“ç°äº†"ä¸‡è±¡å½’å…ƒäºäº‘æ¢"çš„å“²å­¦å†…æ ¸ï¼Œä¸ºç”¨æˆ·åˆ›é€ äº†ä¸€ä¸ªèƒ½æ„ŸçŸ¥ã€å…±æƒ…ã€è¿›åŒ–çš„æ•°å­—ç”Ÿå‘½ä½“ã€‚