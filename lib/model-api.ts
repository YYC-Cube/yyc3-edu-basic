// ç»Ÿä¸€çš„æ¨¡å‹APIè°ƒç”¨æ¥å£

import { localModelDiscovery, type LocalModel } from "./local-models"

export interface ChatMessage {
  role: "system" | "user" | "assistant"
  content: string
}

export interface ModelResponse {
  content: string
  model: string
  usage?: {
    prompt_tokens: number
    completion_tokens: number
    total_tokens: number
  }
}

export class ModelAPI {
  // å‘é€æ¶ˆæ¯åˆ°æŒ‡å®šæ¨¡å‹
  static async sendMessage(
    modelId: string,
    messages: ChatMessage[],
    options?: {
      temperature?: number
      max_tokens?: number
      stream?: boolean
    },
  ): Promise<ModelResponse> {
    // æ£€æŸ¥æ˜¯å¦ä¸ºæœ¬åœ°æ¨¡å‹
    const localModels = localModelDiscovery.getDiscoveredModels()
    const localModel = localModels.find((m) => m.id === modelId)

    if (localModel) {
      return await this.sendToLocalModel(localModel, messages, options)
    } else {
      return await this.sendToCloudModel(modelId, messages, options)
    }
  }

  // å‘é€åˆ°æœ¬åœ°æ¨¡å‹
  private static async sendToLocalModel(
    model: LocalModel,
    messages: ChatMessage[],
    options?: any,
  ): Promise<ModelResponse> {
    try {
      const content = await localModelDiscovery.sendMessage(model, messages)

      return {
        content,
        model: model.id,
        usage: {
          prompt_tokens: this.estimateTokens(messages.map((m) => m.content).join(" ")),
          completion_tokens: this.estimateTokens(content),
          total_tokens: 0,
        },
      }
    } catch (error) {
      throw new Error(`æœ¬åœ°æ¨¡å‹ ${model.name} è°ƒç”¨å¤±è´¥: ${error instanceof Error ? error.message : "æœªçŸ¥é”™è¯¯"}`)
    }
  }

  // å‘é€åˆ°äº‘ç«¯æ¨¡å‹ï¼ˆæ¨¡æ‹Ÿå®ç°ï¼‰
  private static async sendToCloudModel(
    modelId: string,
    messages: ChatMessage[],
    options?: any,
  ): Promise<ModelResponse> {
    // è¿™é‡Œå¯ä»¥é›†æˆçœŸå®çš„äº‘ç«¯API
    // ç›®å‰è¿”å›æ¨¡æ‹Ÿå“åº”
    await new Promise((resolve) => setTimeout(resolve, 1000 + Math.random() * 2000))

    const userMessage = messages[messages.length - 1]?.content || ""
    const response = this.generateMockResponse(userMessage, modelId)

    return {
      content: response,
      model: modelId,
      usage: {
        prompt_tokens: this.estimateTokens(messages.map((m) => m.content).join(" ")),
        completion_tokens: this.estimateTokens(response),
        total_tokens: 0,
      },
    }
  }

  // ç”Ÿæˆæ¨¡æ‹Ÿå“åº”ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
  private static generateMockResponse(input: string, modelId: string): string {
    const lowerInput = input.toLowerCase()

    // æ ¹æ®ä¸åŒæ¨¡å‹è¿”å›ä¸åŒé£æ ¼çš„å›å¤
    const modelStyles = {
      "gpt-4": "ğŸ§  **GPT-4 æ·±åº¦åˆ†æ**\n\n",
      "gpt-3.5": "âš¡ **GPT-3.5 å¿«é€Ÿå›å¤**\n\n",
      "claude-3": "ğŸ“š **Claude-3 è¯¦ç»†è§£ç­”**\n\n",
      "gemini-pro": "ğŸ” **Gemini Pro å¤šç»´åˆ†æ**\n\n",
      "jimeng-ai": "âœ¨ **å³æ¢¦AI åˆ›æ„å›å¤**\n\n",
    }

    const prefix = modelStyles[modelId as keyof typeof modelStyles] || "ğŸ¤– **AIåŠ©æ‰‹å›å¤**\n\n"

    // æ£€æŸ¥è¨€å¯ä¸‡è±¡åˆ›æ„åŠŸèƒ½
    if (["åˆ›æ„", "è®¾è®¡", "æ–‡æ¡ˆ", "å›¾ç‰‡", "è§†é¢‘", "ç”Ÿæˆ", "åˆ¶ä½œ"].some((keyword) => lowerInput.includes(keyword))) {
      return `${prefix}ğŸŒŸ **è¨€å¯ä¸‡è±¡ - AIåˆ›æ„å¹³å°** æ¬¢è¿æ‚¨ï¼

ğŸ­ **åˆ›æ„å·¥åŠå…¨è§ˆï¼š**

ğŸ“ **æ–‡åˆ›å·¥åŠ** - æ™ºèƒ½æ–‡æ¡ˆåˆ›ä½œ
â€¢ è¥é”€æ–‡æ¡ˆã€äº§å“æè¿°ã€æ•…äº‹åˆ›ä½œ
â€¢ è¯—æ­Œç”Ÿæˆã€å‰§æœ¬åˆ›ä½œã€æ–°é—»ç¨¿ä»¶

ğŸ¨ **å³æ¢¦AI** - è§†è§‰åˆ›æ„ç”Ÿæˆ  
â€¢ å›¾åƒç”Ÿæˆã€é£æ ¼è½¬æ¢ã€logoè®¾è®¡
â€¢ æµ·æŠ¥åˆ¶ä½œã€æ’ç”»åˆ›ä½œã€æ¦‚å¿µè®¾è®¡

ğŸ¬ **å½±åƒåˆ›ä½œ** - è§†é¢‘åŠ¨ç”»åˆ¶ä½œ
â€¢ è§†é¢‘å‰ªè¾‘ã€åŠ¨ç”»ç”Ÿæˆã€ç‰¹æ•ˆåˆ¶ä½œ
â€¢ é…éŸ³åˆæˆã€å­—å¹•ç”Ÿæˆã€çŸ­è§†é¢‘åˆ›ä½œ

ğŸ’« **ä½¿ç”¨æ–¹å¼ï¼š**
â€¢ ç›´æ¥æè¿°æ‚¨çš„åˆ›æ„éœ€æ±‚
â€¢ ä¸Šä¼ å‚è€ƒå›¾ç‰‡æˆ–æ–‡æ¡£
â€¢ æŒ‡å®šé£æ ¼ã€è‰²è°ƒã€æƒ…æ„ŸåŸºè°ƒ
â€¢ æˆ‘ä¼šä¸ºæ‚¨æä¾›ä¸“ä¸šçš„åˆ›æ„æ–¹æ¡ˆ

å‡†å¤‡å¥½é‡Šæ”¾æ‚¨çš„åˆ›æ„äº†å—ï¼Ÿå‘Šè¯‰æˆ‘æ‚¨çš„æƒ³æ³•ï¼`
    }

    // ç³»ç»ŸçŠ¶æ€æŸ¥è¯¢
    if (["çŠ¶æ€", "ç³»ç»Ÿ", "è¿è¡Œ"].some((keyword) => lowerInput.includes(keyword))) {
      return `${prefix}ğŸ–¥ï¸ **NEXUS OS ç³»ç»ŸçŠ¶æ€æŠ¥å‘Š**

ğŸŸ¢ **æ ¸å¿ƒæœåŠ¡çŠ¶æ€ï¼š**
â€¢ AI å¼•æ“ï¼šåœ¨çº¿è¿è¡Œ (${modelId})
â€¢ æœ¬åœ°æ¨¡å‹ï¼š${localModelDiscovery.getDiscoveredModels().length} ä¸ªå·²å‘ç°
â€¢ åˆ›æ„å¼•æ“ï¼šé«˜æ€§èƒ½æ¨¡å¼
â€¢ æ•°æ®åº“ï¼šè¿æ¥æ­£å¸¸  
â€¢ ç½‘ç»œæœåŠ¡ï¼šç¨³å®š

ğŸ“Š **æ¨¡å‹çŠ¶æ€ï¼š**
â€¢ å½“å‰æ¨¡å‹ï¼š${modelId}
â€¢ å“åº”å»¶è¿Ÿï¼š${Math.floor(Math.random() * 200 + 50)}ms
â€¢ å¯ç”¨æ€§ï¼š99.9%

ç³»ç»Ÿè¿è¡ŒçŠ¶æ€è‰¯å¥½ï¼Œæ‰€æœ‰åŠŸèƒ½æ­£å¸¸å¯ç”¨ï¼`
    }

    // é»˜è®¤å›å¤
    return `${prefix}æˆ‘æ­£åœ¨ä½¿ç”¨ **${modelId}** æ¨¡å‹ä¸ºæ‚¨æœåŠ¡ã€‚

ğŸ¯ **æˆ‘å¯ä»¥å¸®åŠ©æ‚¨ï¼š**
â€¢ åˆ›æ„å†…å®¹ç”Ÿæˆ - æ–‡æ¡ˆã€å›¾åƒã€è§†é¢‘
â€¢ æ•°æ®åˆ†æå¤„ç† - æŠ¥è¡¨ã€ç»Ÿè®¡ã€å¯è§†åŒ–
â€¢ ç³»ç»ŸåŠŸèƒ½æ“ä½œ - å®¢æˆ·ç®¡ç†ã€è¡¨å•åˆ›å»º
â€¢ æ™ºèƒ½å¯¹è¯äº¤äº’ - é—®ç­”ã€å»ºè®®ã€æŒ‡å¯¼

ğŸ’¡ **ä½¿ç”¨æç¤ºï¼š**
â€¢ è¯¦ç»†æè¿°æ‚¨çš„éœ€æ±‚è·å¾—æ›´å¥½çš„å›å¤
â€¢ å°è¯•è¯´"åˆ›æ„"ä½“éªŒAIå†…å®¹ç”Ÿæˆ
â€¢ è¯´"ç³»ç»ŸçŠ¶æ€"æŸ¥çœ‹è¿è¡Œæƒ…å†µ
â€¢ ä¸Šä¼ æ–‡ä»¶è¿›è¡Œæ‰¹é‡å¤„ç†

æœ‰ä»€ä¹ˆå…·ä½“éœ€è¦å¸®åŠ©çš„å—ï¼Ÿ`
  }

  // ä¼°ç®—tokenæ•°é‡ï¼ˆç®€å•å®ç°ï¼‰
  private static estimateTokens(text: string): number {
    // ä¸­æ–‡æŒ‰å­—ç¬¦è®¡ç®—ï¼Œè‹±æ–‡æŒ‰å•è¯è®¡ç®—
    const chineseChars = (text.match(/[\u4e00-\u9fff]/g) || []).length
    const englishWords = text
      .replace(/[\u4e00-\u9fff]/g, "")
      .split(/\s+/)
      .filter((w) => w.length > 0).length

    return Math.ceil(chineseChars * 1.5 + englishWords)
  }

  // è·å–æ¨¡å‹ä¿¡æ¯
  static async getModelInfo(modelId: string) {
    const localModels = localModelDiscovery.getDiscoveredModels()
    const localModel = localModels.find((m) => m.id === modelId)

    if (localModel) {
      return {
        id: localModel.id,
        name: localModel.name,
        provider: localModel.provider,
        type: "local" as const,
        status: localModel.status,
        capabilities: localModel.capabilities,
        endpoint: localModel.endpoint,
      }
    }

    // äº‘ç«¯æ¨¡å‹ä¿¡æ¯
    const cloudModels = {
      "gpt-4": { name: "GPT-4", provider: "OpenAI", capabilities: ["chat", "reasoning", "code"] },
      "gpt-3.5": { name: "GPT-3.5", provider: "OpenAI", capabilities: ["chat", "completion"] },
      "claude-3": { name: "Claude-3", provider: "Anthropic", capabilities: ["chat", "analysis", "writing"] },
      "gemini-pro": { name: "Gemini Pro", provider: "Google", capabilities: ["chat", "vision", "multimodal"] },
      "jimeng-ai": { name: "å³æ¢¦AI", provider: "JiMeng", capabilities: ["creative", "image", "design"] },
    }

    const cloudModel = cloudModels[modelId as keyof typeof cloudModels]
    if (cloudModel) {
      return {
        id: modelId,
        name: cloudModel.name,
        provider: cloudModel.provider,
        type: "cloud" as const,
        status: "online" as const,
        capabilities: cloudModel.capabilities,
      }
    }

    return null
  }
}
